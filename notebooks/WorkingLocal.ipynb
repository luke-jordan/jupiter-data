{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook using local copy of all events to explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the master DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.read_csv('all_user_events_2020_09_10.zip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove dominant users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df['user_id_count'] = master_df.groupby(['user_id'])['time_transaction_occurred'].transform('count')\n",
    "    \n",
    "# we remove the top 2, because they are team members often testing, so distort\n",
    "outlier_user_ids = master_df['user_id'].value_counts()[:2].index.tolist()\n",
    "# probably a better panda-ninja way to do this but not worth it right now\n",
    "for user_id in outlier_user_ids:\n",
    "    master_df = master_df[master_df.user_id != user_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract primary boost info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf = master_df[master_df['event_type'].str.contains('BOOST_CREATED')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import loads\n",
    "bdf[\"parsed_context\"] = bdf.context.apply(loads) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf[\"boost_id\"] = bdf[\"parsed_context\"].apply(lambda context: context[\"boostId\"])\n",
    "bdf[\"boost_type\"] = bdf[\"parsed_context\"].apply(lambda context: context[\"boostType\"])\n",
    "bdf[\"boost_category\"] = bdf[\"parsed_context\"].apply(lambda context: context[\"boostCategory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf[\"boost_time\"] = pd.to_datetime(bdf[\"time_transaction_occurred\"], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_convertors = { 'WHOLE_CURRENCY': 1, 'WHOLE_CENT': 100, 'HUNDREDTH_CENT': 10000 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_save_requirement(parsed_context):\n",
    "    if 'statusConditions' not in parsed_context:\n",
    "        return None, None\n",
    "    \n",
    "    # we look for the first\n",
    "    conditions = parsed_context['statusConditions']\n",
    "    save_type = None\n",
    "    save_threshold = None\n",
    "    \n",
    "    sought_conditions = ['save_greater_than', 'first_save_above', 'balance_crossed_major_digit', 'balance_crossed_abs_target']\n",
    "    is_save_condition = lambda cond: len([check for check in sought_conditions if cond.startswith(check)]) > 0\n",
    "    \n",
    "    for value in conditions.values():\n",
    "        matches = [cond for cond in value if is_save_condition(cond)]\n",
    "        if (len(matches) == 0):\n",
    "            continue\n",
    "            \n",
    "        condition_clause = matches[0]\n",
    "        save_type = condition_clause[0:condition_clause.find(' ')]\n",
    "        \n",
    "        param_start = condition_clause.find('{') + 1\n",
    "        param_end = condition_clause.find('}')\n",
    "        save_parameter = condition_clause[param_start:param_end].split('::')\n",
    "#         print(save_parameter)\n",
    "        \n",
    "        save_threshold = int(save_parameter[0]) / unit_convertors[save_parameter[1]]\n",
    "                \n",
    "    return save_type, save_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_context = bdf.iloc[0]['parsed_context']\n",
    "example_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_save_requirement(example_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['boost_amount'] = bdf['parsed_context'].apply(lambda context: int(context['boostAmount']) / unit_convertors[context['boostUnit']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf['save_requirements'] = bdf['parsed_context'].apply(extract_save_requirement)\n",
    "bdf[['save_type', 'save_amount']] = pd.DataFrame(bdf['save_requirements'].tolist(), index=bdf.index)\n",
    "bdf[\"boost_save_ratio\"] = bdf[\"save_amount\"] / bdf[\"boost_amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = bdf[[\n",
    "    \"boost_id\",\n",
    "    \"user_id\",\n",
    "    \"boost_time\",\n",
    "    \"boost_type\",\n",
    "    \"boost_category\",\n",
    "    \"save_type\",\n",
    "    \"save_amount\",\n",
    "    \"boost_amount\",\n",
    "    \"boost_save_ratio\",\n",
    "    \"parsed_context\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_open = (example_context['boostEndTime'] - example_context['boostStartTime']) / (24 * 60 * 60 * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain prior saves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = master_df[master_df['event_type'].str.contains('SAVING_PAYMENT_SUCCESSFUL')]\n",
    "sdf[\"save_time\"] = pd.to_datetime(sdf[\"time_transaction_occurred\"], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_prior_saves = lambda boost_row: len(sdf[(sdf[\"save_time\"] < boost_row[\"boost_time\"]) & (sdf[\"user_id\"] == boost_row[\"user_id\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_prior_saves(df.iloc[423])\n",
    "# df.apply(count_prior_saves, axis=1)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf[\"prior_save_count\"] = df.apply(count_prior_saves, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf.prior_save_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract only boosts where saves are required (maybe move earlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf = bdf[bdf.save_type.notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional feature extraction (to come)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf[\"day_of_month\"] = bdf[\"boost_time\"].dt.day\n",
    "bdf[\"day_of_week\"] = bdf[\"boost_time\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_feature_list = [\n",
    "    \"boost_type\",\n",
    "    \"boost_category\",\n",
    "    \"save_type\",\n",
    "    \"save_amount\",\n",
    "    \"boost_amount\",\n",
    "    \"boost_save_ratio\",\n",
    "    \"day_of_month\",\n",
    "    \"day_of_week\",\n",
    "    \"prior_save_count\",\n",
    "    \"save_within_48\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_next_save = lambda boost_row: len(sdf[(sdf[\"save_time\"] < boost_row[\"boost_time\"]) & (sdf[\"user_id\"] == boost_row[\"user_id\"])])\n",
    "def find_next_save(boost_row, time_threshold = 48):\n",
    "    user_mask = sdf[\"user_id\"] == boost_row[\"user_id\"]\n",
    "    save_time_mask = sdf[\"save_time\"] > boost_row[\"boost_time\"]\n",
    "    duration_mask = (sdf[\"save_time\"] - boost_row[\"boost_time\"]).astype('timedelta64[h]') < 48\n",
    "    next_save_df = sdf[user_mask & save_time_mask & duration_mask]\n",
    "    return len(next_save_df) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_of_next = 0\n",
    "row_counter = 8 # just skipping over first one which happens to be withdrawal\n",
    "\n",
    "while count_of_next == 0:\n",
    "    row_counter += 1\n",
    "    boost_row = bdf.iloc[row_counter]\n",
    "    user_mask = sdf[\"user_id\"] == boost_row[\"user_id\"]\n",
    "    save_time_mask = sdf[\"save_time\"] > boost_row[\"boost_time\"]\n",
    "    count_of_next = len(sdf[user_mask & save_time_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Row: ', row_counter)\n",
    "boost_row = bdf.iloc[row_counter]\n",
    "print('Boost time: ', boost_row['boost_time'])\n",
    "user_mask = sdf[\"user_id\"] == boost_row[\"user_id\"]\n",
    "save_time_mask = sdf[\"save_time\"] > boost_row[\"boost_time\"]\n",
    "duration_mask = (sdf[\"save_time\"] - boost_row[\"boost_time\"]).astype('timedelta64[h]') < 48\n",
    "sdf[user_mask & save_time_mask & duration_mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf[\"save_within_48\"] = bdf.apply(find_next_save, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf.save_within_48.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and do DABL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dabl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = bdf[final_feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dabl_data = dabl.clean(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dabl.plot(dabl_data, target_col='save_within_48')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dabl_data.drop(\"save_within_48\", axis=1)\n",
    "Y = dabl_data.save_within_48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = dabl.EasyPreprocessor()\n",
    "X_trans = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = dabl.SimpleClassifier(random_state=0).fit(X_trans, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up SKL, eval, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, auc, roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = bdf[final_feature_list]\n",
    "feature_df.to_csv('boost_induce_full_extract_aug27.csv', index=False)\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = pd.get_dummies(feature_df, prefix_sep=\"_\", columns=[\"boost_type\", \"boost_category\", \"day_of_week\", \"save_type\"]).drop('save_within_48', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_encoded, feature_df.save_within_48, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=X_train, label=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree Booster Parameters [for the moment pulling these from xgboost repo example for binary classification]\n",
    "# step size shrinkage\n",
    "eta = 1.0\n",
    "# minimum loss reduction required to make a further partition\n",
    "gamma = 1.0\n",
    "# minimum sum of instance weight(hessian) needed in a child\n",
    "min_child_weight = 1\n",
    "# maximum depth of a tree\n",
    "max_depth = 3\n",
    "\n",
    "# Task Parameters\n",
    "# the number of round to do boosting\n",
    "num_round = 2\n",
    "# 0 means do not save any model except the final round model\n",
    "save_period = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Parameters\n",
    "# choose the linear booster\n",
    "# booster = ''\n",
    "\n",
    "# Change Tree Booster Parameters into Linear Booster Parameters\n",
    "# L2 regularization term on weights, default 0\n",
    "lt_lambda = 0.01\n",
    "# L1 regularization term on weights, default 0\n",
    "alpha = 0.01\n",
    "# L2 regularization term on bias, default 0\n",
    "lambda_bias = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_param = {'max_depth':max_depth, 'eta':eta, 'objective':'binary:logistic' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clf = xgb.train(xg_param, data_dmatrix, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_proba = xg_clf.predict(xgb.DMatrix(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number predictions: ', len(preds_proba), ' and first few: ', preds_proba[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should fit threshold tbh, though loss important, since turns out that (suppose logical w/ very unbalanced set)\n",
    "# accuracy is inversely related to fscore, i.e., raising threshold ups accuracy, though clearly spuriously\n",
    "threshold = 0.5\n",
    "preds_class = preds_proba > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert preds_class.shape == Y_test.shape\n",
    "print('Number of positives: ', np.count_nonzero(preds_class), ' and negative: ', np.count_nonzero(preds_class == False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number positive predictions: ', )\n",
    "print('Precision etc: ', precision_recall_fscore_support(Y_test, preds_class, average='binary'))\n",
    "print('Accuracy: ', accuracy_score(Y_test, preds_class))\n",
    "print('ROC AUC: ', roc_auc_score(Y_test, preds_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(xg_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(xg_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X_encoded.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[:100,:], X_encoded.iloc[:100,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"boost_save_ratio\", shap_values, X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_encoded, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupiter-ml] *",
   "language": "python",
   "name": "conda-env-jupiter-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
