{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import dabl\n",
    "\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_monthly_save_aggregates():\n",
    "    sql = \"\"\"\n",
    "        select EXTRACT(MONTH from TIMESTAMP_MILLIS(time_transaction_occurred)) as save_month, unit, \n",
    "            sum(amount) as sum, avg(amount) as average, count(*) as count from ops.user_behaviour \n",
    "            where transaction_type = 'SAVING_EVENT' group by save_month, unit order by save_month desc;\n",
    "    \"\"\"\n",
    "    \n",
    "    df = client.query(sql).to_dataframe()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_boosts_with_saves():\n",
    "    sql = \"\"\"\n",
    "        with boost_offers as (\n",
    "            select *, TIMESTAMP_MILLIS(created_at) as creation_timestamp \n",
    "            from ops.all_user_events \n",
    "            where event_type like 'BOOST_CREATED%'\n",
    "\n",
    "    ), save_events as (\n",
    "            select *, TIMESTAMP_MILLIS(created_at) as creation_timestamp \n",
    "            from ops.all_user_events \n",
    "            where event_type = 'SAVING_PAYMENT_SUCCESSFUL'\n",
    "    )\n",
    "    select boost_offers.user_id, boost_offers.event_type, boost_offers.context, \n",
    "        boost_offers.creation_timestamp as boost_creation_time, save_events.creation_timestamp as save_completion_time,  \n",
    "        TIMESTAMP_DIFF(save_events.creation_timestamp, boost_offers.creation_timestamp, HOUR) as time_from_boost_to_save\n",
    "    from boost_offers left join save_events on boost_offers.user_id = save_events.user_id\n",
    "    where \n",
    "        TIMESTAMP_DIFF(save_events.creation_timestamp, boost_offers.creation_timestamp, HOUR) > 0 \n",
    "        or TIMESTAMP_DIFF(save_events.creation_timestamp, boost_offers.creation_timestamp, HOUR) is null\n",
    "    \"\"\"\n",
    "    \n",
    "    df = client.query(sql).to_dataframe()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_and_construct_labels(boosts_with_saves):\n",
    "    unit_convertors = { 'WHOLE_CURRENCY': 1, 'WHOLE_CENT': 100, 'HUNDREDTH_CENT': 10000 }\n",
    "    \n",
    "    df = boosts_with_saves\n",
    "    df['user_id_count'] = boosts_with_saves.groupby(['user_id'])['boost_creation_time'].transform('count')\n",
    "    \n",
    "    # we remove the top 2, because they are team members often testing, so distort\n",
    "    outlier_user_ids = df['user_id'].value_counts()[:2].index.tolist()\n",
    "    # probably a better panda-ninja way to do this but not worth it right now\n",
    "    for user_id in outlier_user_ids:\n",
    "        df = df[df.user_id != user_id]\n",
    "    \n",
    "    # and here we have our real label     \n",
    "    df[\"is_save_within_day\"] = df[\"time_from_boost_to_save\"] < 24\n",
    "    \n",
    "    # extract a bunch of context from the boosts    \n",
    "    df[\"parsed_context\"] = df.context.apply(json.loads)\n",
    "    df[\"boost_id\"] = df[\"parsed_context\"].apply(lambda context: context[\"boostId\"])\n",
    "    df[\"boost_amount_whole_currency\"] = df[\"parsed_context\"].apply(\n",
    "        lambda context: context[\"boostAmount\"] / unit_convertors[context[\"boostUnit\"]])\n",
    "    \n",
    "    df[\"boost_type\"] = df[\"parsed_context\"].apply(lambda context: context[\"boostType\"])\n",
    "    df[\"boost_category\"] = df[\"parsed_context\"].apply(lambda context: context[\"boostCategory\"])\n",
    "    \n",
    "    df[\"day_of_month\"] = df[\"boost_creation_time\"].dt.day\n",
    "    df[\"hour_of_day\"] = df[\"boost_creation_time\"].dt.hour\n",
    "    \n",
    "    # and this functions as our index     \n",
    "    df[\"boost_user_id\"] = df[\"boost_id\"] + \"::\" + df[\"user_id\"]\n",
    "    \n",
    "    # and finally we strip out the surplus boost-save pairs (by retaining only the opening)\n",
    "    slimmed_df = df.sort_values(\"save_completion_time\").groupby(\"boost_user_id\", as_index=False).first()\n",
    "    \n",
    "    return slimmed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(data):\n",
    "    features_of_interest = [\n",
    "        \"boost_amount_whole_currency\", \n",
    "        \"day_of_month\", \n",
    "        \"hour_of_day\", \n",
    "        \"boost_type\", \n",
    "        \"boost_category\", \n",
    "        \"is_save_within_day\"\n",
    "    ]\n",
    "    stripped_df = data[features_of_interest]\n",
    "    return stripped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosts_with_saves = obtain_boosts_with_saves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clean_up_and_construct_labels(boosts_with_saves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.is_save_within_day.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_frame = feature_extraction(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dabl_data = dabl.clean(feature_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dabl.plot(dabl_data, 'is_save_within_day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = dabl.SimpleClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dabl_data.drop(\"is_save_within_day\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dabl_data.is_save_within_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupiter-ml] *",
   "language": "python",
   "name": "conda-env-jupiter-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
